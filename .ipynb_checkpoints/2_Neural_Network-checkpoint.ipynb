{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project \\#4: Find the “Largest” Digit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 : Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc # to visualize on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_data = np.loadtxt(\"../Datasets/sample_x.csv\", delimiter=\",\") \n",
    "y_data = np.loadtxt(\"../Datasets/sample_y.csv\", delimiter=\",\") \n",
    "\n",
    "x_data = x_data.reshape(-1, 64, 64) # reshape \n",
    "y_data = y_data.reshape(-1, 1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import timeit \n",
    "\n",
    "class Network(object):\n",
    "    #initialize network object\n",
    "    def __init__(self, sizes):\n",
    "        self.sizes = sizes\n",
    "        self.num_layers = len(sizes)\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "        \n",
    "    #Method sends input through trained neural network and outputs values\n",
    "    def Feed_Forward(self, input_data):\n",
    "        for biases, weights in zip(self.biases, self.weights):\n",
    "            z = np.dot(weights, input_data) + biases\n",
    "            input_data = sigmoid(z, derivative = False)\n",
    "        return input_data\n",
    "    \n",
    "    #Cost Function: C(weights, biases) = (1/2n) Sigma_x {y(x) - Output}^2\n",
    "    #need to compute dC/dW\n",
    "    def Stocastic_Gradient_Descent(self, training_data, epochs, batch_size, learning_rate):\n",
    "        start_time = timeit.default_timer()\n",
    "        print \"Beginning Stochastic Gradient Descent:\"\n",
    "        n = len(training_data)\n",
    "        for i in range(epochs):\n",
    "            #print \"      Epoch #\", i+1\n",
    "            np.random.shuffle(training_data)\n",
    "            batches = [training_data[k: k + batch_size] for k in range(0, n, batch_size)]\n",
    "            for batch in batches:\n",
    "                self.SGD_Batch(batch, learning_rate)\n",
    "        stop_time = timeit.default_timer()\n",
    "        print \"Stochastic Gradient Descent Done\"\n",
    "        print \"SGD ran in \", stop_time - start_time, \"seconds.\"\n",
    "\n",
    "        \n",
    "    #single step of SGD for each batch\n",
    "    def SGD_Batch(self, mini_batch, learning_rate):\n",
    "        #gradient step for weights/biases start as array of zeros\n",
    "        Gradient_biases = [np.zeros(b.shape) for b in self.biases]\n",
    "        Gradient_weights = [np.zeros(w.shape) for w in self.weights]\n",
    "        \n",
    "        #for each training example (x, y) in the given batch of training data:\n",
    "        for x, y in mini_batch:\n",
    "            #compute the dC/dW and dC/db for single image in the batch\n",
    "            d_Gradient_biases, d_Gradient_weights = self.Back_Propogation(x, y)\n",
    "            Gradient_biases = [gradb + deltagradb for gradb, deltagradb  in zip(Gradient_biases, d_Gradient_biases)]\n",
    "            Gradient_weights = [gradw + deltagradw for gradw, deltagradw in zip(Gradient_weights, d_Gradient_weights)]\n",
    "        self.weights = [w - (learning_rate/len(mini_batch)) * dw for w, dw in zip(self.weights, Gradient_weights)]\n",
    "        self.biases = [b - (learning_rate/len(mini_batch)) * db for b, db in zip(self.biases, Gradient_biases)]\n",
    "                \n",
    "    def Back_Propogation(self, x, y):\n",
    "        Gradient_biases = [np.zeros(b.shape) for b in self.biases]\n",
    "        Gradient_weights = [np.zeros(w.shape) for w in self.weights]\n",
    "        a = x\n",
    "        activations = []\n",
    "        activations.append(a)\n",
    "        z_vectors = []       \n",
    "        \n",
    "        # feedforward step to obtain the output values \n",
    "        for bias, weight  in zip(self.biases, self.weights):\n",
    "            z = np.dot(weight, a) + bias\n",
    "            a = sigmoid(z, derivative = False)\n",
    "            z_vectors.append(z)\n",
    "            activations.append(a)   \n",
    "            \n",
    "        #Start of back propogation at output nodes:\n",
    "        delta = (activations[-1] - y) * sigmoid(z_vectors[-1], derivative = True)\n",
    "        Gradient_biases[-1] = delta\n",
    "        Gradient_weights[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        \n",
    "        #propogate backwards to previous layers:\n",
    "        for l in range(2, self.num_layers):\n",
    "            z = z_vectors[-l]\n",
    "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sigmoid(z, derivative  = True)\n",
    "            Gradient_biases[-l] = delta\n",
    "            Gradient_weights[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "        return (Gradient_biases, Gradient_weights)\n",
    "    \n",
    "    def evaluate(self, test_data):\n",
    "        print \"Evaluating the training_data\"\n",
    "        test_results = [(np.argmax(self.Feed_Forward(x)), np.argmax(y)) for (x, y) in test_data]\n",
    "        value  = sum(int(x == y) for (x, y) in test_results)\n",
    "        return test_results\n",
    "        \n",
    "        \n",
    "def sigmoid(z, derivative):\n",
    "    sig = 1.0 / (1.0 + np.exp(-z))\n",
    "    if derivative == False:\n",
    "        return sig\n",
    "    else:\n",
    "        return sig * (1 - sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-172-d6a3402c1d6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcropCenter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnew_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minput_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtraining_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-4142045918a3>\u001b[0m in \u001b[0;36mpreprocessImage\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# group and get bounds of hand written digits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mbinCoords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroupPoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinCoords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mbounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetBounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-4142045918a3>\u001b[0m in \u001b[0;36mgroupPoints\u001b[0;34m(binCoords)\u001b[0m\n\u001b[1;32m      5\u001b[0m         distances = np.array([\n\u001b[1;32m      6\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mgrp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         ])\n\u001b[1;32m      9\u001b[0m         \u001b[0mwithInPixDist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mPIX_DISTANCE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new_x = [cropCenter(preprocessImage(a), (28,28)).flatten() for a in x_data]\n",
    "new_x = [x.reshape((len(x),1)) for x in new_x]\n",
    "input_len = len(new_x[0])\n",
    "training_data = zip(new_x, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_y(y):\n",
    "    y = map(int, y)\n",
    "    new_y = np.zeros(10)\n",
    "    new_y[y] = 1.0\n",
    "    return new_y.T.reshape((10,1))\n",
    "\n",
    "new_y_data = [preprocess_y(y) for y in y_data]\n",
    "training_data = zip(new_x, new_y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Network on  10000  preprocessed training images\n",
      "Beginning Stochastic Gradient Descent:\n",
      "Stochastic Gradient Descent Done\n",
      "SGD ran in  32.1673550606 seconds.\n"
     ]
    }
   ],
   "source": [
    "print \"Training Network on \", len(training_data),\" preprocessed training images\" \n",
    "net = Network([input_len, 75, 20, 10])\n",
    "net.Stocastic_Gradient_Descent(training_data, 10, 50, 5)   # epochs, batch_size, learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the training_data\n",
      "0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-180-c2bad7bb205a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "results = net.evaluate(training_data)\n",
    "print results[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = 0\n",
    "result = net.Feed_Forward(new_x[b])\n",
    "\n",
    "print \"Output vector: \", result\n",
    "print \"True digit: \", y_data[b]\n",
    "print \"Neural Net : \", np.argmax(result)\n",
    "img = new_x[b].reshape((28,28))\n",
    "\n",
    "plt.imshow(img, cmap='binary', interpolation='nearest')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
